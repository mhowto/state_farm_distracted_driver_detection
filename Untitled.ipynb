{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\")`\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:82: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (3, 3, 3, 64) not compatible with provided weight shape (64, 3, 3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d75e215d5e3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# set the weights to layer-k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VGG16 model weights have been successfully loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m   1202\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (3, 3, 3, 64) not compatible with provided weight shape (64, 3, 3, 3)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This program is used to recognize the driver's status (one of the 10 statuses) based on the image using pre-trained VGG16 \n",
    "deep convolutional neural network (CNN).\n",
    "This program is modified from the blog post: \n",
    "\"Building powerful image classification models using very little data\" from blog.keras.io.\n",
    "This program do fine tunning for a modified VGG16 net, which consists of two parts: \n",
    "the lower model: layer 0-layer24 of the original VGG16 net  (frozen the first 4 blocks, train the weights of the 5-th block \n",
    "with our dataset)\n",
    "the upper model: newly added two layer dense net (train the weights using our dataset)\n",
    "'''\n",
    "\n",
    "import os\n",
    "#The h5py package is a Pythonic interface to the HDF5 binary data format\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "''' path to the model weights file in HDF5 binary data format\n",
    "The vgg16 weights can be downloaded from the link below:\n",
    "https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view\n",
    "'''\n",
    "weights_path = 'data/vgg16_weights.h5' \n",
    "\n",
    "# dimensions of the images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# the path to the training data\n",
    "train_data_dir = 'data/train'\n",
    "# the path to the validation data\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# the number of training samples. We have 20924 training images, but actually we can set the \n",
    "# number of training samples can be augmented to much more, for example 2*20924\n",
    "nb_train_samples =  17943\n",
    "\n",
    "# We actually have 1500 validation samples, which can be augmented to much more\n",
    "nb_validation_samples = 4481\n",
    "\n",
    "# number of epoches for training\n",
    "nb_epoch = 10\n",
    "\n",
    "# build the VGG16 model\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "'''\n",
    "# load the weights of the VGG16 networks (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "'''\n",
    "# load the weights for each layer\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    weights[0] = np.transpose(np.array(weights[0])[:, :, ::-1, ::-1], (2, 3, 1, 0))\n",
    "    # set the weights to layer-k\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('VGG16 model weights have been successfully loaded.')\n",
    "\n",
    "# build a MLP classifier model to put on top of the VGG16 model\n",
    "top_model = Sequential()\n",
    "# flateen the output of VGG16 model to 2D Numpy matrix (n*D)\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "# hidden layer of 256 neurons\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "# add dropout for the dense layer\n",
    "top_model.add(Dropout(0.5))\n",
    "# the output layer: we have 10 claases\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# connect the two models onto the VGG16 net\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block) of VGFG16 net to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# compile the model \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "# augmentation configuration for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "# augmentation configuration for validation data (actually we did no augmentation to teh validation images)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# training data generator from folder\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), \n",
    "                                                  batch_size=32, class_mode='categorical')\n",
    "\n",
    "# validation data generator from folder\n",
    "validation_generator = train_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), \n",
    "                                                       batch_size=32, class_mode='categorical')\n",
    "\n",
    "# fit the model\n",
    "model.fit_generator(train_generator, samples_per_epoch=nb_train_samples, nb_epoch=nb_epoch, \n",
    "                    validation_data=validation_generator, nb_val_samples=nb_validation_samples)\n",
    "\n",
    "# save the model weights\n",
    "# model.save_weights('VGG16_and_MLP_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
