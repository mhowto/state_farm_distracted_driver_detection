{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/shauk/.conda/envs/tensorflow/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess import read_and_normalize_train_data, read_and_normalize_test_data2, save_submission\n",
    "import numpy as np\n",
    "import time\n",
    "from vgg16_run import save_model, read_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224\n",
    "batch_size = 32\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet50_model():\n",
    "    base_model = ResNet50(include_top=False, input_shape=(224,224,3))\n",
    "    resnet50_output = base_model.output\n",
    "    predictions = Dense(10, activation='softmax')(Flatten()(resnet50_output))\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name='resnet50'\n",
    "nfolds = 10\n",
    "kf = KFold(n_splits=nfolds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train use ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('data/train', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validate_generator = train_datagen.flow_from_directory('data/validation', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 616s 308ms/step - loss: 2.0387 - acc: 0.2997 - val_loss: 1.8525 - val_acc: 0.4361\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 612s 306ms/step - loss: 1.7180 - acc: 0.4654 - val_loss: 1.5943 - val_acc: 0.5605\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 1.5295 - acc: 0.5448 - val_loss: 1.4655 - val_acc: 0.5434\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 1.3941 - acc: 0.5976 - val_loss: 1.3372 - val_acc: 0.6203\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 617s 308ms/step - loss: 1.2831 - acc: 0.6392 - val_loss: 1.2436 - val_acc: 0.6642\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 615s 307ms/step - loss: 1.1987 - acc: 0.6733 - val_loss: 1.1597 - val_acc: 0.6977\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 620s 310ms/step - loss: 1.1217 - acc: 0.7002 - val_loss: 1.0843 - val_acc: 0.7358\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 618s 309ms/step - loss: 1.0580 - acc: 0.7257 - val_loss: 1.0401 - val_acc: 0.7392\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 617s 309ms/step - loss: 1.0044 - acc: 0.7416 - val_loss: 0.9907 - val_acc: 0.7498\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 615s 307ms/step - loss: 0.9518 - acc: 0.7603 - val_loss: 0.9430 - val_acc: 0.7545\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 0.9119 - acc: 0.7735 - val_loss: 0.9167 - val_acc: 0.7677\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 613s 306ms/step - loss: 0.8695 - acc: 0.7891 - val_loss: 0.8492 - val_acc: 0.8060\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 0.8339 - acc: 0.8001 - val_loss: 0.8307 - val_acc: 0.8029\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 0.8026 - acc: 0.8078 - val_loss: 0.8074 - val_acc: 0.8157\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 615s 307ms/step - loss: 0.7702 - acc: 0.8192 - val_loss: 0.7539 - val_acc: 0.8222\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 614s 307ms/step - loss: 0.7442 - acc: 0.8264 - val_loss: 0.7455 - val_acc: 0.8183\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 621s 310ms/step - loss: 0.7191 - acc: 0.8318 - val_loss: 0.7179 - val_acc: 0.8253\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 627s 313ms/step - loss: 0.6936 - acc: 0.8386 - val_loss: 0.7023 - val_acc: 0.8347\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 628s 314ms/step - loss: 0.6734 - acc: 0.8458 - val_loss: 0.6638 - val_acc: 0.8514\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 629s 314ms/step - loss: 0.6527 - acc: 0.8501 - val_loss: 0.6467 - val_acc: 0.8523\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resnet50'\n",
    "model = resnet50_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=2000, epochs=20, validation_data=validate_generator, validation_steps=800)\n",
    "save_model(model, 100, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory('data/test', target_size=(224,224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = test_generator.filenames\n",
    "test_ids = [d.strip('c0/') for d in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492/2492 [==============================] - 552s 222ms/step\n"
     ]
    }
   ],
   "source": [
    "#model = read_model(100, model_name)\n",
    "test_prediction = model.predict_generator(test_generator, verbose=1)\n",
    "save_submission(test_ids, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 with 2 layer fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet50_model_02():\n",
    "    base_model = ResNet50(include_top=False, input_shape=(224,224,3))\n",
    "    resnet50_output = base_model.output\n",
    "    fc1 = Dense(4096, activation='softmax')(Flatten()(resnet50_output))\n",
    "    predictions = Dense(10, activation='softmax')(fc1)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('data/train', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validate_generator = validate_datagen.flow_from_directory('data/validation', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 612s 306ms/step - loss: 2.0393 - acc: 0.3018 - val_loss: 1.8265 - val_acc: 0.4533\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 608s 304ms/step - loss: 1.7193 - acc: 0.4630 - val_loss: 1.6177 - val_acc: 0.5091\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 608s 304ms/step - loss: 1.5288 - acc: 0.5428 - val_loss: 1.4428 - val_acc: 0.5927\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 610s 305ms/step - loss: 1.3908 - acc: 0.6001 - val_loss: 1.3353 - val_acc: 0.6427\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 610s 305ms/step - loss: 1.2841 - acc: 0.6404 - val_loss: 1.2342 - val_acc: 0.6648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93e52e1a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'resnet50_with_2_fc'\n",
    "model = resnet50_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=2000, epochs=5, validation_data=validate_generator, validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, 5, 'resnet50_with2_fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "2492/2492 [==============================] - 540s 217ms/step\n"
     ]
    }
   ],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Image Generator with Preprocessing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#train_datagen = ImageDataGenerator(rescale=1./255, )\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=(0.85, 1.1),\n",
    "    channel_shift_range=10.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)\n",
    "train_generator = train_datagen.flow_from_directory('data/train', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=(0.85, 1.1),\n",
    "    channel_shift_range=10.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False)\n",
    "validate_generator = validate_datagen.flow_from_directory('data/validation', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 1167s 583ms/step - loss: 0.7724 - acc: 0.7445 - val_loss: 0.4284 - val_acc: 0.8623\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 1156s 578ms/step - loss: 0.3517 - acc: 0.8869 - val_loss: 0.2969 - val_acc: 0.9044\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 1156s 578ms/step - loss: 0.2645 - acc: 0.9156 - val_loss: 0.2125 - val_acc: 0.9354\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 1160s 580ms/step - loss: 0.2178 - acc: 0.9312 - val_loss: 0.2328 - val_acc: 0.9250\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 1156s 578ms/step - loss: 0.1925 - acc: 0.9378 - val_loss: 0.1783 - val_acc: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9326c41d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'resnet50_with_2_fc'\n",
    "model = resnet50_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=2000, epochs=5, validation_data=validate_generator, validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "2492/2492 [==============================] - 542s 218ms/step\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory('data/test', target_size=(224,224), batch_size=batch_size, class_mode=None, shuffle=False)\n",
    "test_ids = test_generator.filenames\n",
    "test_ids = [d.strip('c0/') for d in test_ids]\n",
    "test_prediction = model.predict_generator(test_generator, verbose=1)\n",
    "save_submission(test_ids, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = [d.strip('c0/') for d in test_ids]\n",
    "save_submission(test_ids, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
