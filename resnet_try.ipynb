{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess import read_and_normalize_train_data, read_and_normalize_test_data\n",
    "import numpy as np\n",
    "import time\n",
    "from vgg16_run import save_model, read_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224\n",
    "batch_size = 32\n",
    "nb_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train from cache!\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(x_train, [0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 224, 224, 3) 13501759488\n",
      "(22424, 10) 896960\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_train.nbytes)\n",
    "print(y_train.shape, y_train.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model():\n",
    "    base_model = ResNet50(include_top=False, input_shape=(224,224,3))\n",
    "    resnet50_output = base_model.output\n",
    "    predictions = Dense(10, activation='softmax')(Flatten()(resnet50_output))\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 1.2970 - val_loss: 8.4777\n",
      "Epoch 2/2\n",
      "16144/16144 [==============================] - 57s 4ms/step - loss: 0.7305 - val_loss: 9.3233\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16144/16144 [==============================] - 60s 4ms/step - loss: 1.2881 - val_loss: 7.6468\n",
      "Epoch 2/2\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.7330 - val_loss: 8.8532\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 1.3125 - val_loss: 9.9864\n",
      "Epoch 2/2\n",
      "16144/16144 [==============================] - 56s 3ms/step - loss: 0.7407 - val_loss: 10.7227\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 1.2988 - val_loss: 8.9471\n",
      "Epoch 2/2\n",
      "16144/16144 [==============================] - 55s 3ms/step - loss: 0.7404 - val_loss: 10.2502\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 61s 4ms/step - loss: 1.2871 - val_loss: 8.6320\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 57s 4ms/step - loss: 0.7359 - val_loss: 9.4385\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 64s 4ms/step - loss: 1.3015 - val_loss: 6.5394\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.7496 - val_loss: 7.5448\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 65s 4ms/step - loss: 1.2934 - val_loss: 7.9590\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.7349 - val_loss: 8.7032\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 66s 4ms/step - loss: 1.2877 - val_loss: 8.3326\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.7403 - val_loss: 9.0487\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 67s 4ms/step - loss: 1.3041 - val_loss: 7.8283\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.7401 - val_loss: 8.8063\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/2\n",
      "16145/16145 [==============================] - 70s 4ms/step - loss: 1.2999 - val_loss: 8.8800\n",
      "Epoch 2/2\n",
      "16145/16145 [==============================] - 61s 4ms/step - loss: 0.7436 - val_loss: 9.7058\n"
     ]
    }
   ],
   "source": [
    "num_fold = 0\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    num_fold += 1\n",
    "    x = x_train[train_index]\n",
    "    y = y_train[train_index]\n",
    "    \n",
    "    model = resnet50_model()\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=nb_epoch,\n",
    "             verbose=1, validation_split=0.2, shuffle=True)\n",
    "    \n",
    "    save_model(model, num_fold, model_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-21d808ed0c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "del x\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3325/79726 [00:09<03:49, 332.57it/s]/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 90%|█████████ | 71961/79726 [04:39<00:30, 257.41it/s]"
     ]
    }
   ],
   "source": [
    "num_fold=11\n",
    "from vgg16_run import read_model, merge_several_folds_mean\n",
    "print('Start testing............')\n",
    "test_data, test_id = read_and_normalize_test_data(img_rows, img_cols, 3)\n",
    "yfull_test = []\n",
    "\n",
    "for index in range(1, num_fold + 1):\n",
    "    # Store test predictions\n",
    "    model = read_model(index, model_name)\n",
    "    test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "info_string = 'loss_' + modelStr \\\n",
    "    + '_r_' + str(img_rows) \\\n",
    "    + '_c_' + str(img_cols) \\\n",
    "    + '_folds_' + str(nfolds) \\\n",
    "    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "test_res = merge_several_folds_mean(yfull_test, nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  6  7 10 14 15 17 19 20 22 23]\n",
      "[ 0  1  2  5  8  9 11 12 13 16 18 21]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.8",
   "language": "python",
   "name": "tensorflow1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
