{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess import read_and_normalize_train_data, read_and_normalize_test_data2, save_submission\n",
    "import numpy as np\n",
    "import time\n",
    "from vgg16_run import save_model, read_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224\n",
    "batch_size = 32\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model():\n",
    "    base_model = ResNet50(include_top=False, input_shape=(224,224,3))\n",
    "    resnet50_output = base_model.output\n",
    "    predictions = Dense(10, activation='softmax')(Flatten()(resnet50_output))\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='resnet50'\n",
    "nfolds = 10\n",
    "kf = KFold(n_splits=nfolds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore train from cache!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c2fcaea7c100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_drivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_normalize_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Notebooks/state_farm_distracted_driver_detection/data_preprocess.py\u001b[0m in \u001b[0;36mread_and_normalize_train_data\u001b[0;34m(img_rows, img_cols, color_type)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_drivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mtrain_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, y_train, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(x_train, [0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 224, 224, 3) 13501759488\n",
      "(22424, 10) 896960\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_train.nbytes)\n",
    "print(y_train.shape, y_train.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16144/16144 [==============================] - 61s 4ms/step - loss: 1.2970 - val_loss: 8.4777\n",
      "Epoch 2/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.7305 - val_loss: 9.3233\n",
      "Epoch 3/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.5522 - val_loss: 10.3952\n",
      "Epoch 4/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.4580 - val_loss: 10.2753\n",
      "Epoch 5/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.3904 - val_loss: 10.5330\n",
      "Epoch 6/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3441 - val_loss: 11.2860\n",
      "Epoch 7/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.3088 - val_loss: 11.0965\n",
      "Epoch 8/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2837 - val_loss: 11.7367\n",
      "Epoch 9/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.2617 - val_loss: 11.3355\n",
      "Epoch 10/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2462 - val_loss: 11.3519\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16144/16144 [==============================] - 62s 4ms/step - loss: 1.2945 - val_loss: 8.5521\n",
      "Epoch 2/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.7415 - val_loss: 9.7746\n",
      "Epoch 3/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.5580 - val_loss: 10.7671\n",
      "Epoch 4/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.4609 - val_loss: 11.4424\n",
      "Epoch 5/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.3910 - val_loss: 11.5795\n",
      "Epoch 6/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3433 - val_loss: 11.9894\n",
      "Epoch 7/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.3100 - val_loss: 12.1767\n",
      "Epoch 8/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2836 - val_loss: 12.3076\n",
      "Epoch 9/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.2593 - val_loss: 13.3274\n",
      "Epoch 10/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2439 - val_loss: 13.7749\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16144/16144 [==============================] - 62s 4ms/step - loss: 1.2899 - val_loss: 7.2994\n",
      "Epoch 2/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.7441 - val_loss: 8.2117\n",
      "Epoch 3/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.5576 - val_loss: 8.4351\n",
      "Epoch 4/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.4565 - val_loss: 8.7475\n",
      "Epoch 5/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3947 - val_loss: 9.0912\n",
      "Epoch 6/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3458 - val_loss: 9.9168\n",
      "Epoch 7/10\n",
      "16144/16144 [==============================] - 58s 4ms/step - loss: 0.3099 - val_loss: 9.7528\n",
      "Epoch 8/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2827 - val_loss: 10.0980\n",
      "Epoch 9/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2597 - val_loss: 10.8342\n",
      "Epoch 10/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2449 - val_loss: 11.1045\n",
      "Train on 16144 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16144/16144 [==============================] - 63s 4ms/step - loss: 1.3084 - val_loss: 9.2114\n",
      "Epoch 2/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.7394 - val_loss: 10.1011\n",
      "Epoch 3/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.5596 - val_loss: 10.8549\n",
      "Epoch 4/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.4605 - val_loss: 11.1002\n",
      "Epoch 5/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3926 - val_loss: 12.1179\n",
      "Epoch 6/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3420 - val_loss: 11.7456\n",
      "Epoch 7/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.3085 - val_loss: 12.5261\n",
      "Epoch 8/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2808 - val_loss: 12.3038\n",
      "Epoch 9/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2597 - val_loss: 12.8758\n",
      "Epoch 10/10\n",
      "16144/16144 [==============================] - 59s 4ms/step - loss: 0.2424 - val_loss: 12.7108\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 65s 4ms/step - loss: 1.2876 - val_loss: 8.5791\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.7410 - val_loss: 9.4045\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.5595 - val_loss: 10.0754\n",
      "Epoch 4/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.4590 - val_loss: 9.8911\n",
      "Epoch 5/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3895 - val_loss: 10.7847\n",
      "Epoch 6/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3433 - val_loss: 10.0962\n",
      "Epoch 7/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3094 - val_loss: 10.4629\n",
      "Epoch 8/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2810 - val_loss: 10.4882\n",
      "Epoch 9/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2601 - val_loss: 11.3894\n",
      "Epoch 10/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2412 - val_loss: 11.3263\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 65s 4ms/step - loss: 1.2991 - val_loss: 8.8068\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.7348 - val_loss: 10.0549\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.5535 - val_loss: 10.6253\n",
      "Epoch 4/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.4590 - val_loss: 10.8470\n",
      "Epoch 5/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3914 - val_loss: 11.1528\n",
      "Epoch 6/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3443 - val_loss: 11.5466\n",
      "Epoch 7/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3059 - val_loss: 11.8658\n",
      "Epoch 8/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2815 - val_loss: 11.7985\n",
      "Epoch 9/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2609 - val_loss: 12.0123\n",
      "Epoch 10/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2370 - val_loss: 12.4685\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 68s 4ms/step - loss: 1.2983 - val_loss: 9.4274\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.7396 - val_loss: 10.2194\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.5521 - val_loss: 10.9628\n",
      "Epoch 4/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.4598 - val_loss: 11.4908\n",
      "Epoch 5/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.3883 - val_loss: 11.3246\n",
      "Epoch 6/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.3456 - val_loss: 12.0990\n",
      "Epoch 7/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.3108 - val_loss: 11.8427\n",
      "Epoch 8/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.2783 - val_loss: 11.7444\n",
      "Epoch 9/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.2572 - val_loss: 12.2739\n",
      "Epoch 10/10\n",
      "16145/16145 [==============================] - 62s 4ms/step - loss: 0.2428 - val_loss: 12.6589\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 70s 4ms/step - loss: 1.2875 - val_loss: 8.1244\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.7386 - val_loss: 8.9074\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.5528 - val_loss: 9.0849\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.4544 - val_loss: 9.2893\n",
      "Epoch 5/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.3896 - val_loss: 9.2205\n",
      "Epoch 6/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.3452 - val_loss: 9.2623\n",
      "Epoch 7/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.3142 - val_loss: 9.8142\n",
      "Epoch 8/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.2836 - val_loss: 10.0353\n",
      "Epoch 9/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.2621 - val_loss: 10.1639\n",
      "Epoch 10/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.2427 - val_loss: 10.2998\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 68s 4ms/step - loss: 1.2792 - val_loss: 7.6076\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.7342 - val_loss: 8.5648\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.5528 - val_loss: 9.0281\n",
      "Epoch 4/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.4626 - val_loss: 9.7174\n",
      "Epoch 5/10\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.3902 - val_loss: 9.8390\n",
      "Epoch 6/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3450 - val_loss: 10.4202\n",
      "Epoch 7/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.3112 - val_loss: 10.1028\n",
      "Epoch 8/10\n",
      "16145/16145 [==============================] - 60s 4ms/step - loss: 0.2820 - val_loss: 10.2384\n",
      "Epoch 9/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2624 - val_loss: 10.9613\n",
      "Epoch 10/10\n",
      "16145/16145 [==============================] - 59s 4ms/step - loss: 0.2441 - val_loss: 11.3844\n",
      "Train on 16145 samples, validate on 4037 samples\n",
      "Epoch 1/10\n",
      "16145/16145 [==============================] - 71s 4ms/step - loss: 1.2947 - val_loss: 8.7147\n",
      "Epoch 2/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.7329 - val_loss: 9.6018\n",
      "Epoch 3/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.5469 - val_loss: 9.6403\n",
      "Epoch 4/10\n",
      "16145/16145 [==============================] - 63s 4ms/step - loss: 0.4517 - val_loss: 10.1426\n",
      "Epoch 5/10\n",
      " 9248/16145 [================>.............] - ETA: 20s - loss: 0.3975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7e7d24be651b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     model.fit(x, y, batch_size=batch_size, epochs=nb_epoch,\n\u001b[0;32m---> 10\u001b[0;31m              verbose=1, validation_split=0.2, shuffle=True)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_fold = 0\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    num_fold += 1\n",
    "    x = x_train[train_index]\n",
    "    y = y_train[train_index]\n",
    "    \n",
    "    model = resnet50_model()\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=nb_epoch,\n",
    "             verbose=1, validation_split=0.2, shuffle=True)\n",
    "    \n",
    "    save_model(model, num_fold, model_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-21d808ed0c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "del x\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train use ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('data/train', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validate_generator = train_datagen.flow_from_directory('data/validate', target_size=(224,224), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 747s 373ms/step - loss: 0.3859 - val_loss: 4.8687\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 750s 375ms/step - loss: 0.0785 - val_loss: 5.8291\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 750s 375ms/step - loss: 0.0403 - val_loss: 6.6897\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 753s 377ms/step - loss: 0.0253 - val_loss: 7.3702\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 751s 376ms/step - loss: 0.0167 - val_loss: 7.6039\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resnet50'\n",
    "model = resnet50_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=2000, epochs=5, validation_data=validate_generator, validation_steps=800)\n",
    "save_model(model, 100, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c0/img_10.jpg',\n",
       " 'c0/img_100.jpg',\n",
       " 'c0/img_1000.jpg',\n",
       " 'c0/img_100000.jpg',\n",
       " 'c0/img_100001.jpg',\n",
       " 'c0/img_100002.jpg',\n",
       " 'c0/img_100003.jpg',\n",
       " 'c0/img_100004.jpg',\n",
       " 'c0/img_100005.jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory('data/test', target_size=(224,224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_generator.filenames\n",
    "test_ids = [d.strip('c0/') for d in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492/2492 [==============================] - 695s 279ms/step\n"
     ]
    }
   ],
   "source": [
    "model = read_model(100, model_name)\n",
    "test_prediction = model.predict_generator(test_generator, verbose=1)\n",
    "save_submission(test_ids, np.array(yfull_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/10381 [00:00<00:29, 352.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3945/10381 [00:09<00:16, 395.68it/s]/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 10381/10381 [00:26<00:00, 396.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 26.18 seconds\n",
      "Directory doesn't exists\n",
      "(10381, 3, 224, 224)\n",
      "10381/10381 [==============================] - 35s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8666/8666 [00:21<00:00, 394.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 22.0 seconds\n",
      "Directory doesn't exists\n",
      "(8666, 3, 224, 224)\n",
      "8666/8666 [==============================] - 31s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8614/8614 [00:21<00:00, 404.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.3 seconds\n",
      "Directory doesn't exists\n",
      "(8614, 3, 224, 224)\n",
      "8614/8614 [==============================] - 31s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8669/8669 [00:21<00:00, 401.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.6 seconds\n",
      "Directory doesn't exists\n",
      "(8669, 3, 224, 224)\n",
      "8669/8669 [==============================] - 31s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8683/8683 [00:21<00:00, 402.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.61 seconds\n",
      "Directory doesn't exists\n",
      "(8683, 3, 224, 224)\n",
      "8683/8683 [==============================] - 32s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8676/8676 [00:21<00:00, 402.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.59 seconds\n",
      "Directory doesn't exists\n",
      "(8676, 3, 224, 224)\n",
      "8676/8676 [==============================] - 32s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8659/8659 [00:21<00:00, 400.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.65 seconds\n",
      "Directory doesn't exists\n",
      "(8659, 3, 224, 224)\n",
      "8659/8659 [==============================] - 33s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8670/8670 [00:21<00:00, 399.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 21.73 seconds\n",
      "Directory doesn't exists\n",
      "(8670, 3, 224, 224)\n",
      "8670/8670 [==============================] - 34s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8708/8708 [00:22<00:00, 395.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 22.05 seconds\n",
      "Directory doesn't exists\n",
      "(8708, 3, 224, 224)\n",
      "8708/8708 [==============================] - 34s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_paths = ['data/test/p'+str(i) for i in range(1,10)]\n",
    "\n",
    "from vgg16_run import merge_several_folds_mean\n",
    "print('Start testing............')\n",
    "\n",
    "nfolds = 2\n",
    "yfull_test = []\n",
    "test_ids = []\n",
    "for test_path in test_paths:\n",
    "    test_data, test_id = read_and_normalize_test_data2(img_rows, img_cols, test_path, 3)\n",
    "    print(test_data.shape)\n",
    "    test_ids = test_ids + test_id\n",
    "    \n",
    "    test_data = np.transpose(test_data, (0,2,3,1))\n",
    "    model = read_model(100, model_name)\n",
    "    test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "    yfull_test = yfull_test + test_prediction.tolist()    \n",
    "    \n",
    "\n",
    "info_string = 'loss_' + model_name \\\n",
    "    + '_r_' + str(img_rows) \\\n",
    "    + '_c_' + str(img_cols) \\\n",
    "    + '_folds_' + str(100) \\\n",
    "    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "save_submission(test_ids, np.array(yfull_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = ['data/test/p'+str(i) for i in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/10381 [00:00<00:28, 358.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3954/10381 [00:09<00:16, 395.79it/s]/home/alpha/anaconda3/envs/tensorflow1.8/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 10381/10381 [00:26<00:00, 395.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 26.25 seconds\n",
      "Directory doesn't exists\n",
      "(10381, 3, 224, 224)\n",
      "10381/10381 [==============================] - 38s 4ms/step\n",
      "10381/10381 [==============================] - 37s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/8666 [00:00<00:27, 313.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 10381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8666/8666 [00:23<00:00, 368.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.56 seconds\n",
      "Directory doesn't exists\n",
      "(8666, 3, 224, 224)\n",
      "8666/8666 [==============================] - 33s 4ms/step\n",
      "8666/8666 [==============================] - 33s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/8614 [00:00<00:27, 317.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 19047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8614/8614 [00:23<00:00, 369.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.34 seconds\n",
      "Directory doesn't exists\n",
      "(8614, 3, 224, 224)\n",
      "8614/8614 [==============================] - 34s 4ms/step\n",
      "8614/8614 [==============================] - 34s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8669 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 27661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8669/8669 [00:23<00:00, 365.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.74 seconds\n",
      "Directory doesn't exists\n",
      "(8669, 3, 224, 224)\n",
      "8669/8669 [==============================] - 36s 4ms/step\n",
      "8669/8669 [==============================] - 35s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/8683 [00:00<00:28, 298.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 36330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8683/8683 [00:23<00:00, 366.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.71 seconds\n",
      "Directory doesn't exists\n",
      "(8683, 3, 224, 224)\n",
      "8683/8683 [==============================] - 36s 4ms/step\n",
      "8683/8683 [==============================] - 35s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/8676 [00:00<00:27, 318.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 45013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8676/8676 [00:24<00:00, 361.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 24.03 seconds\n",
      "Directory doesn't exists\n",
      "(8676, 3, 224, 224)\n",
      "8676/8676 [==============================] - 37s 4ms/step\n",
      "8676/8676 [==============================] - 38s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/8659 [00:00<00:28, 303.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 53689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8659/8659 [00:23<00:00, 368.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.53 seconds\n",
      "Directory doesn't exists\n",
      "(8659, 3, 224, 224)\n",
      "8659/8659 [==============================] - 37s 4ms/step\n",
      "8659/8659 [==============================] - 38s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/8670 [00:00<00:29, 289.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 62348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8670/8670 [00:23<00:00, 364.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.78 seconds\n",
      "Directory doesn't exists\n",
      "(8670, 3, 224, 224)\n",
      "8670/8670 [==============================] - 40s 5ms/step\n",
      "8670/8670 [==============================] - 40s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/8708 [00:00<00:26, 323.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfull_test.len: 71018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8708/8708 [00:23<00:00, 365.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 23.82 seconds\n",
      "Directory doesn't exists\n",
      "(8708, 3, 224, 224)\n",
      "8708/8708 [==============================] - 41s 5ms/step\n",
      "8708/8708 [==============================] - 42s 5ms/step\n",
      "yfull_test.len: 79726\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result/submission_2018-05-05_22:09:05.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f46d303e2de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0minfo_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loss_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;34m'_r_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;34m'_c_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;34m'_folds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0;34m'_ep_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msave_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myfull_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Notebooks/state_farm_distracted_driver_detection/data_preprocess.py\u001b[0m in \u001b[0;36msave_submission\u001b[0;34m(image_ids, predictions)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result/submission_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d_%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c6'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'c9'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result/submission_2018-05-05_22:09:05.csv'"
     ]
    }
   ],
   "source": [
    "from vgg16_run import merge_several_folds_mean\n",
    "print('Start testing............')\n",
    "\n",
    "nfolds = 2\n",
    "yfull_test = []\n",
    "test_ids = []\n",
    "for test_path in test_paths:\n",
    "    test_data, test_id = read_and_normalize_test_data2(img_rows, img_cols, test_path, 3)\n",
    "    print(test_data.shape)\n",
    "    test_ids = test_ids + test_id\n",
    "    y_test = []\n",
    "    test_data = np.transpose(test_data, (0,2,3,1))\n",
    "    for index in range(1, nfolds+1):\n",
    "        # Store test predictions\n",
    "        model = read_model(index, model_name)\n",
    "        test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "        y_test.append(test_prediction)\n",
    "    yfull_test = yfull_test + merge_several_folds_mean(y_test, nfolds)\n",
    "    print('yfull_test.len:', len(yfull_test))\n",
    "\n",
    "info_string = 'loss_' + model_name \\\n",
    "    + '_r_' + str(img_rows) \\\n",
    "    + '_c_' + str(img_cols) \\\n",
    "    + '_folds_' + str(nfolds) \\\n",
    "    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "save_submission(test_ids, yfull_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfull_test= np.array(yfull_test)\n",
    "save_submission(test_ids, yfull_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "def split_train_data(train_path, validate_path, ratio=0.2):\n",
    "    np.random.seed(42)\n",
    "    for c in os.listdir(train_path):\n",
    "        vpath = os.path.join(validate_path, c)\n",
    "        tpath = os.path.join(train_path, c)\n",
    "        os.mkdir(vpath)\n",
    "        files = os.listdir(tpath)\n",
    "        size = len(files)\n",
    "        perm = np.random.permutation(size)\n",
    "        selected = perm[:int(size*ratio)]\n",
    "        for idx in selected:\n",
    "            f = files[idx]\n",
    "            tfile = os.path.join(tpath, f)\n",
    "            shutil.move(tfile, vpath)\n",
    "        print('classes {} done'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes c5 done\n",
      "classes c8 done\n",
      "classes c3 done\n",
      "classes c1 done\n",
      "classes c0 done\n",
      "classes c9 done\n",
      "classes c2 done\n",
      "classes c7 done\n",
      "classes c6 done\n",
      "classes c4 done\n"
     ]
    }
   ],
   "source": [
    "split_train_data('data/train', 'data/validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.8",
   "language": "python",
   "name": "tensorflow1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
